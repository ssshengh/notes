# 基础知识

在并发场景中，内存的控制变得较为微妙，这一篇基础知识主要是涵盖了内存顺序和内存控制方面的高级知识。

# CachePadded

crossbeam 中提供了一个辅助的数据结构`CachePadded`，它的主要作用是：

> - 在并发编程中，更新原子值会使其所在的整个缓存行失效，这将导致在其他CPU内核上访问该缓存行的速度下降。
> - `CachePadded`类可以确保更新一部分数据不会使其他缓存数据失效，主要是通过更改 aligment 达到目的的。
> - 设备上的缓存行长度可能会有所不同，文本列举了x86-64, aarch64, powerpc64等各类设备上的缓存行长度假设值。
> - `CachePadded<T>`的大小是可以容纳类型为`T`的值的N字节的最小倍数，其中N为设备上的缓存行长度；`CachePadded<T>`的对齐方式为N字节和`T`的对齐方式中的较大者。

## 内存对齐与缓存

### 对齐

这里需要回顾一下 CPU 对齐与缓存的基础知识，数据的alignment（对齐）在计算机系统中主要影响以下几个方面：

1. **性能**：数据对齐可以加快内存访问的速度。当数据与硬件的储存单元对齐时，CPU可以一次读取完整的数据块，而不需要分多次读取。若数据不对齐，电脑可能需要用更多的CPU周期来读写数据，从而导致性能降低。
2. **硬件要求**：某些硬件平台要求数据在内存中以特定方式对齐。如，在某些CPU架构中，如果某类型的数据不对齐，将导致硬件异常和程序崩溃。
3. **内存使用**：数据对齐可能会导致内存空间的浪费。为了满足对齐要求，编译器可能会在数据之间插入填充位，这会占用额外的内存空间。然而，这种内存的浪费通常比起它带来的性能提升来说是可以接受的。

总的来说，正确地对齐数据可以使硬件更有效率地处理数据，提高程序的运行性能，减少出错的机会，但也可能带来一定程度的内存浪费。

### 缓存

CPU内核的缓存通常由多个缓存行（cache lines）构成。

当CPU需要访问内存中的数据时，它会以缓存行为单位从内存中取数据，并将这些数据存储在它的缓存中。缓存行的大小因处理器而异，通常为64字节或128字节。每个缓存行保存了一块连续的内存数据和这块数据的地址信息。

由于空间局部性，程序接下来可能会访问这块内存附近的其他数据，如果这些数据也在同一个缓存行中，CPU可以直接从缓存中获取这些数据，而无需从内存中取，这大大提高了数据访问的速度。

> 举个🌰：假设Intel Core i7处理器的L1缓存大小为32KB，那么这个缓存被分成两个部分：一个16KB的数据缓存和一个16KB的指令缓存。在这款处理器中，每个缓存行的大小为64字节。所以，如果只查看数据缓存，那么可以说，16KB的数据缓存包含了256个缓存行（16KB / 64B = 256）。这些缓存行用于存储处理器可能会需要的数据，从而加快了处理器读取和存储数据的速度。
>
> **每个核心**都有自己独立的32KB的L1缓存。即每个处理器核心都有一个16KB的数据缓存和一个16KB的指令缓存。因此，对于一个拥有4个核心的Intel Core i7处理器，总共就会有128KB的L1缓存（32KB x 4）。此外，这些核心通常还会共享一些更大的二级（L2）和三级（L3）缓存，这些缓存可以帮助加速多核间的数据访问和协同工作。

![image-20230617235540455](/Users/bytedance/Library/Application Support/typora-user-images/image-20230617235540455.png)

当发生缓存未命中（cache miss）时，CPU通常会从内存中**获取需要的缓存行，而不是整个缓存**。

在CPU访问内存中的数据时，它常常需要的只是其中一部分数据，但CPU会以缓存行（cache line）为单位，加载更多的数据到缓存里。这是因为有一个称作局部性原理（principle of locality）的观察结果：如果一个数据被访问，那么它附近的数据在不久的将来也很可能被访问。因此，当缓存未命中时，CPU会从内存中获取缺失的缓存行，并存入CPU缓存中。这样下次CPU访问这个缓存行中的其他数据时，就可以直接从CPU缓存中获取，而不需要再次访问内存，从而提高了数据访问的速度。

## 设计

从上面的基础知识可以看出，问题的关键在于不同平台下的缓存行的大小，如果我们把数据对齐到缓存行一样大或者缓存行的倍数，那么如果更改数据的话将只会导致这个缓存行被重新加载和同步，而不会影响其他的数据：

>`CachePadded<T>`的大小是可以容纳类型为`T`的值的N字节的最小倍数，其中N为设备上的缓存行长度；`CachePadded<T>`的对齐方式为N字节和`T`的对齐方式中的较大者。

```rust
#[cfg_attr(
    any(
        target_arch = "x86_64",
        target_arch = "aarch64",
        target_arch = "powerpc64",
    ),
    repr(align(128))
)]
/// .... 还有其他处理器
#[cfg_attr(
    not(any(
        target_arch = "x86_64",
        target_arch = "aarch64",
        target_arch = "powerpc64",
        target_arch = "arm",
        target_arch = "mips",
        target_arch = "mips64",
        target_arch = "riscv32",
        target_arch = "riscv64",
        target_arch = "sparc",
        target_arch = "hexagon",
        target_arch = "m68k",
        target_arch = "s390x",
    )),
    repr(align(64))
)]
pub struct CachePadded<T> {
    value: T,
}

/// 并发安全保证是由 T 来完成的。
unsafe impl<T: Send> Send for CachePadded<T> {}
unsafe impl<T: Sync> Sync for CachePadded<T> {}

// 一些很基础的引用方法实现。
impl<T> CachePadded<T> {
    /// Pads and aligns a value to the length of a cache line.
    ///
    /// # Examples
    ///
    /// ```
    /// use crossbeam_utils::CachePadded;
    ///
    /// let padded_value = CachePadded::new(1);
    /// ```
    pub const fn new(t: T) -> CachePadded<T> {
        CachePadded::<T> { value: t }
    }

    /// Returns the inner value.
    ///
    /// # Examples
    ///
    /// ```
    /// use crossbeam_utils::CachePadded;
    ///
    /// let padded_value = CachePadded::new(7);
    /// let value = padded_value.into_inner();
    /// assert_eq!(value, 7);
    /// ```
    pub fn into_inner(self) -> T {
        self.value
    }
}

impl<T> Deref for CachePadded<T> {
    type Target = T;

    fn deref(&self) -> &T {
        &self.value
    }
}

impl<T> DerefMut for CachePadded<T> {
    fn deref_mut(&mut self) -> &mut T {
        &mut self.value
    }
}

impl<T: fmt::Debug> fmt::Debug for CachePadded<T> {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("CachePadded")
            .field("value", &self.value)
            .finish()
    }
}

impl<T> From<T> for CachePadded<T> {
    fn from(t: T) -> Self {
        CachePadded::new(t)
    }
}
```

# 原子读写与 volatile

![image-20230619235025514](/Users/bytedance/Library/Application Support/typora-user-images/image-20230619235025514.png)

上面的图是一个启发，我在看`crossbeam::duque::Buffer`的实现的实现发现这么一个注释：

```rust
    /// Writes `task` into the specified `index`.
    ///
    /// This method might be concurrently called with another `read` at the same index, which is
    /// technically speaking a data race and therefore UB. We should use an atomic store here, but
    /// that would be more expensive and difficult to implement generically for all types `T`.
    /// Hence, as a hack, we use a volatile write instead.
    unsafe fn write(&self, index: isize, task: MaybeUninit<T>) {
        ptr::write_volatile(self.at(index).cast::<MaybeUninit<T>>(), task)
    }

    /// Reads a task from the specified `index`.
    ///
    /// This method might be concurrently called with another `write` at the same index, which is
    /// technically speaking a data race and therefore UB. We should use an atomic load here, but
    /// that would be more expensive and difficult to implement generically for all types `T`.
    /// Hence, as a hack, we use a volatile load instead.
    unsafe fn read(&self, index: isize) -> MaybeUninit<T> {
        ptr::read_volatile(self.at(index).cast::<MaybeUninit<T>>())
    }
```

"Volatile" 这个术语一般用在硬件编程中，意味这个操作不能被编译器优化掉或者重排序。这使得开发者可以对某些特定的内存位置进行直接的读写，这在与硬件设备交互时尤为关键。volatile 提醒编译器它后面所定义的变量随时都有可能改变，因此编译后的程序每次需要存储或读取这个变量的时候，告诉编译器对该变量不做优化，**都会直接从变量内存地址中读取数据，从而可以提供对特殊地址的稳定访问**。

如果没有volatile关键字，则编译器可能优化读取和存储，**可能暂时使用寄存器中的值**，如果这个变量由别的程序更新了的话，将出现不一致的现象。（简洁的说就是：volatile关键词影响编译器编译的结果，用volatile声明的变量表示该变量随时可能发生变化，与该变量有关的运算，不要进行编译优化，以免出错）。

然而，从来没有说过 **volatile 保证内存顺序**！

当我们谈论原子存储和加载（atomic store/load）时，我们指的是一种特殊的存储和加载操作，该操作保证了在多线程环境中对于某一数据的访问和修改不会被打断。这种保证是为了防止出现并发问题，例如数据竞态（data race）。原子操作由处理器直接支持，通常需要特殊的处理器指令来实现。这就意味着原子操作通常的执行时间比普通的内存操作要长。因此，我们说原子操作在性能上“更昂贵”。

现代的处理器通常有多个执行核心，可能会有多个核心同时读写同一块内存。在这种情况下，为了维护内存一致性，处理器必须在所有核心之间同步这个原子操作。这个同步过程也需要时间，进一步增加了原子操作的代价。

此外，原子操作在编程上也更复杂。为所有类型`T`泛型地实现一个原子存储或加载需要借助于特殊的语言特性，如`std::sync::atomic::AtomicUsize`。尽管Rust的标准库提供了一些基本类型的原子版本，但是任意类型的原子版本是不存在的。

相比之下，`volatile`操作在硬件层面上不需要保证多核同步，因此在性能上“更便宜”。在编程上也更简单，因为只需要使用`core::ptr::write_volatile`或`core::ptr::read_volatile`即可。然而，`volatile`操作不能阻止数据竞态，因此如果可能存在多线程写入的情况下，使用它可能会导致未定义的行为。
